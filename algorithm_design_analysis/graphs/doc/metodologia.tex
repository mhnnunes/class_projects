\section{Metodologia} \label{sec:metodologia}

O objetivo desta seção é apresentar a metodologia utilizada na implementação do trabalho prático. A partir do formalismo introduzido na seção \ref{sec:formalizacao}, apresenta-se as decisões de implementação e as estruturas de dados utilizadas. Será fornecido também uma análise assintótica de complexidade das principais funções do programa.


O trabalho foi implementado utilizando a linguagem C++, logo, a complexidade das operações será analisada utilizando como base os valores descritos no \texttt{cppreference}\footnote{\url{https://en.cppreference.com/w/}}. A estrutura principal utilizada é uma classe \texttt{Graph}, que internamente contém: um array \texttt{vector<Node> nodes} (representando os nós do grafo), um array \texttt{vector<char> visited} que indica se cada nó foi visitado (foi utilizado \texttt{char} pois este tipo consome apenas um byte de memória), e uma variável \texttt{vector< vector<int> > parent} para salvar os nós ancestrais de cada nó do grafo. A \texttt{struct Node}, por sua vez, possui um array de inteiros \texttt{vector<int> adj} contendo as posições dos nós adjacentes ao atual, uma variável \texttt{unsigned int position} indicando a posição do nó na componente, e uma variável \texttt{int CC} indicando em qual componente o nó se encontra.

Inicialmente, um grafo vazio é criado, e o vetor de nós é alocado com o número de nós lido da entrada ($O(\textbar V \textbar )$). Em seguida, a leitura das arestas é realizada, e um inteiro é adicionado em cada uma das listas de adjacência dos nós da aresta, utilizando \texttt{adj.push\_back} (complexidade $O(1)$ amortizada). Portanto, ao final da adição das $\textbar E \textbar$ arestas, temos no total uma complexidade $O(\textbar V \textbar + \textbar E \textbar )$ para a leitura e montagem do grafo, em tempo e espaço.

A fim de \textbf{dividir o grafo em componentes conexas}, foi utilizado o algoritmo \ref{alg:dfs} (busca em profundidade). A complexidade de tempo da busca em profundidade é comprovadamente $\Theta(\textbar V \textbar + \textbar E \textbar)$ \cite{cormen2009introduction}. Os dados das componentes foram salvos em um array \texttt{vector< struct CC >}, onde cada objeto de \texttt{struct CC} contém: um array \texttt{vector<int> nodes\_in\_cc} contendo os índices dos nós presentes na componente, uma variável \texttt{int nvertices} contendo o número de nós neste array, uma variável \texttt{int number\_of\_arcs} contendo o numero de arestas na componente, uma variável \texttt{int maxdegree} contendo o maior grau entre os nós na componente, uma variável \texttt{start\_node} contendo o nó inicial da componente (útil para caminhos), uma variável \texttt{int mintime} que salva a menor distância entre os pares de nós na componente, e uma variável \texttt{CC\_type type} indicando o tipo de grafo da componente (\texttt{CC\_type} é um \texttt{enum} com as opções \texttt{\{path, cycle, tree, bipartite\}}). A complexidade de memória deste array é dominada pelo array de nós em cada objeto \texttt{CC}. Como cada nó do grafo está em exatamente uma componente, e os outros elementos da estrutura são $O(1)$ (constantes) em memória, o array \texttt{vector< struct CC >} utilizará $O(\textbar V \textbar)$ memória extra.

O \textbf{reconhecimento do tipo de cada componente }(nave) foi realizado seguindo o algoritmo \ref{alg:check_CC}. O algoritmo percorre cada uma das componentes $s_i \in S$, acessando características que são obtidas em $O(1)$ (tempo constante), como descrito no parágrafo anterior. Sabemos pela especificação do trabalho pratico que o número $k$ de componentes é limitado superiormente pelo número de vértices $\textbar V \textbar$. Logo, o algoritmo executa em tempo $O(k) << O(\textbar V \textbar)$.

Um passo intermediário é realizado, para permitir que este cálculo do tempo de vantagem seja feito de maneira mais eficiente. Foi realizado um \textbf{pré-processamento nas componentes}, de forma diferente para cada tipo de componente, identificado no passo anterior. Foram realizadas as seguintes ações: 

\begin{itemize}
	\item \textbf{Caminho e ciclo}: foi atribuído um valor inteiro para cada um dos nós, sequencialmente. Desta forma, para calcular a distância entre dois nós, basta calcular o valor absoluto da diferença entre os dois identificadores dos nós. A atribuição dos identtificadores para o grafo caminho foi realizada utilizando uma execução da \texttt{DFSVisit} (presente no algoritmo \ref{alg:dfs}), partindo de um nó de grau 1 (uma das pontas do caminho). Para o grafo ciclo, o mesmo procedimento foi utilizado, porém partindo de qualquer um dos nós. A distância entre os nós $1$ e $3$ na figura \ref{fig:nave_rec} seria 2, por exemplo. A distância entre os nós em um ciclo, entretanto, é calculada usando a fórmula $d(a, b) = min(\textbar a - b \textbar, n - \textbar a - b \textbar) $, onde $n$ é o número de nós do ciclo. A fórmula é utilizada pois em um ciclo, a menor distância pode passar por um dos dois caminhos possíveis a cada nó. Usando como exemplo a figura \ref{fig:nave_transp}, $d(1, 3) = 2$, mas $d(1,7) = 2$ também. Complexidade do pré-processamento $O(\textbar V \textbar)$ em tempo e espaço. Complexidade da consulta: $O(1)$ em tempo e espaço.
	\item \textbf{Bipartido completo}: inicialmente seleciona-se um nó aleatório $u$ da componente, e atribui-se o identificador $0$ para este nó. Para todos os $v_i$ adjacentes a $u$, atribui-se o identificador $1$. A distância entre dois nós será $1$ caso os identificadores sejam diferentes (estão cada um em uma partição da componente), e $2$ caso os identificadores sejam iguais (estão na mesma partição, logo a dois passos de distância). Complexidade do pré-processamento $O(\textbar V \textbar)$ em tempo e espaço. Complexidade da consulta: $O(1)$ em tempo e espaço.
	\item \textbf{Árvore}: a fim de calcular a distância entre dois nós em uma árvore, foi utilizada uma técnica chamada de LCA (Lowest Common Ancestor), com consultas feitas utilizando Binary Lifting\footnote{\url{https://cp-algorithms.com/graph/lca_binary_lifting.html}}. Esta abordagem calcula o nó da árvore que é o ancestral mais próximo dos dois nós $(a, b)$ que estão na consulta, e então calcula-se a distância dos dois nós a este ancestral, e retorna a soma como resposta. Utiliza-se a matriz  \texttt{vector< vector<int> > parent} como memória, com complexidade $O(\textbar V \textbar log(\textbar V \textbar ))$ em espaço. A complexidade de tempo do pré-processamento também é $O(\textbar V \textbar log(\textbar V \textbar ))$ (executar \texttt{DFS} construindo a matriz \texttt{parent}), e a consulta \texttt{lca(a, b)} tem complexidade \texttt{log(\textbar V \textbar)}.
\end{itemize}

O último passo do algoritmo é o \textbf{cálculo do tempo de vantagem}. Este cálculo é feito percorrendo cada uma das componentes $s_i \in S$, e calculando a menor distância entre seus nós que serão trocados de posição. Aplica-se o lema \ref{lem:lemma_1}, e o menor valor encontrado entre todas as componentes é retornado. A complexidade de tempo desta etapa é no máximo $O(\textbar V \textbar log(\textbar V \textbar ))$, quando todas as $O(\textbar V \textbar)$ consultas são realizadas em uma árvore, cujo tempo de consulta é $O(log(\textbar V \textbar ))$. 

Pode-se concluir que a complexidade assintótica total do programa é a soma da complexidade dos passos intermediários, logo $O(2(\textbar V \textbar + \textbar E \textbar) + k + 2(\textbar V \textbar log(\textbar V \textbar)) )$. A mesma análise serve para a complexidade em memória: $O( (\textbar V \textbar + \textbar E \textbar) + \textbar V \textbar + \textbar V \textbar log(\textbar V \textbar))$. Caso o grafo seja denso ($\textbar E \textbar \approx \textbar V \textbar^2$), as complexidades serão dominadas pelo primeiro termo, e serão $O(\textbar E \textbar) = O(\textbar V \textbar^2)$. Caso contrário, serão dominadas pelo último termo, sendo $O(\textbar V \textbar log(\textbar V \textbar))$.


